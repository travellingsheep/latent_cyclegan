# Latent CycleGAN config (SD1.5 VAE latent .pt)

data:
  # Two unpaired domains (each contains many .pt)
  a_dir: "./pt_dataset/trainA"
  b_dir: "./pt_dataset/trainB"

  # IMPORTANT: your .pt latents are NOT scaled by 0.18215
  # - If False: decode uses latents directly (recommended for your case)
  # - If True: decode will divide by vae_scaling_factor before VAE.decode
  latents_scaled: false

  # Extra latent scaling for training stability:
  # model_input = raw_latent / latent_divisor
  # visualization decode uses raw_latent = model_latent * latent_divisor
  latent_divisor: 1

model:
  in_channels: 4
  out_channels: 4
  # Smaller than image CycleGAN
  ngf: 256
  ndf: 64
  n_res_blocks: 9
  d_layers: 3
  # For latents, default is unconstrained output
  out_activation: "none"  # one of: none, tanh

train:
  device: "cuda"   # "cuda" or "cpu"
  seed: 42
  epochs: 200
  batch_size: 4
  num_workers: 4
  amp: true

  # Checkpoints
  checkpoint_dir: "outputs/model"
  resume: true
  # If empty, will try {checkpoint_dir}/last.pt
  resume_path: ""
  resume_restore_rng: true

  # CycleGAN replay buffer (for discriminator updates)
  # 0 means disabled
  fake_buffer_size: 50
  fake_buffer_prob: 0.5

  lr: 0.0002
  beta1: 0.5
  beta2: 0.999

  # LR schedule (CycleGAN paper): keep lr for 100 epochs, then linearly decay to 0 over next 100
  lr_constant_epochs: 100
  lr_decay_epochs: 100

  # Paper: "divide the objective by 2 while optimizing D"
  d_loss_scale: 0.5

  # CycleGAN loss weight
  lambda_cyc: 2.0

  # Identity loss: L_id = E_y||G(y)-y||1 + E_x||F(x)-x||1
  # Common practice: total adds (lambda_cyc * lambda_id) * L_id
  lambda_id: 0.1

logging:
  # tqdm fixed width; bar length is fixed via bar_format
  tqdm_ncols: 120
  tqdm_bar_len: 30

  log_dir: "outputs/logs"
  log_file: "train_log.jsonl"

visualization:
  every_epochs: 1
  out_dir: "outputs/vis"
  num_samples: 2

  # VAE for decoding latents -> RGB (for visualization only)
  # Examples:
  # - "runwayml/stable-diffusion-v1-5" with subfolder "vae"
  # - "stabilityai/sd-vae-ft-mse" (no subfolder)
  vae_model_name_or_path: "runwayml/stable-diffusion-v1-5"
  vae_subfolder: "vae"
  vae_scaling_factor: 0.18215

# Evaluation config for eval_latent_cyclegan.py
eval:
  # If empty, evaluator will use {train.checkpoint_dir}/last.pt
  checkpoint_path: ""
  out_dir: "outputs/eval"
  # Default test image dirs in this repo
  testA_dir: "datasets/testA"
  testB_dir: "datasets/testB"

  # Optional: CLIP config (transformers)
  clip_model_id: "openai/clip-vit-base-patch32"
  clip_cache_dir: ""
  clip_local_files_only: false
  clip_use_safetensors: true

  # Optional: write relative paths in metrics.csv and store roots in metrics_paths.json
  compact_paths: false

  # Metrics & speed
  image_size: 256
  batch_size: 8
  max_src_samples: 0
  max_ref_cache: 256
  max_ref_compare: 50
  cache_dir: "outputs/eval_cache"
  force_regen_cache: false

  save_images: true
  disable_lpips: false
  disable_clip: false
  amp_bf16: true
  device: "cuda"

# Evaluation config for eval_cyclegan_yaml.py (original image-space CycleGAN)
cyclegan_eval:
  # Where the original repo stores checkpoints: {checkpoints_dir}/{name}/{epoch}_net_G_A.pth
  checkpoints_dir: "checkpoints"
  name: "monet2photo_cyclegan"
  epoch: "latest"

  out_dir: "outputs/eval_cyclegan"
  testA_dir: "datasets/monet2photo/testA"
  testB_dir: "datasets/monet2photo/testB"

  image_size: 256
  batch_size: 8
  max_src_samples: 0
  max_ref_cache: 256
  max_ref_compare: 100
  cache_dir: "outputs/eval_cache_cyclegan"
  force_regen_cache: false

  save_images: true
  disable_lpips: false
  disable_clip: false
  amp_bf16: true
  device: "cuda"

  # Optional: CLIP config (transformers)
  clip_model_id: "openai/clip-vit-base-patch32"
  clip_cache_dir: ""
  clip_local_files_only: false
  clip_use_safetensors: false

  # Optional: write relative paths in metrics.csv and store roots in metrics_paths.json
  compact_paths: true

  model:
    input_nc: 3
    output_nc: 3
    ngf: 64
    netG: "resnet_9blocks"
    norm: "instance"
    no_dropout: true
